round_tbl <- function(df) {
df %>%
mutate(
across(c(y2019, y2024, change), ~ round(.x, -1)),   # -3 = thousands
pct_change = round(pct_change, 1)                   # 0.1 pp
)
}
occ_neg  <- occ_neg  %>% round_tbl()
ind_neg  <- ind_neg  %>% round_tbl()
# ── 6.  Inspect results ─────────────────────────────────────────────────────
occ_neg %>% arrange(pct_change) %>% print(n = 20)   # worst-hit occupations
ind_neg %>% arrange(pct_change) %>% print(n = 20)   # worst-hit industries
# ── 5.  Industries (IND) ────────────────────────────────────────────────────
#       IND == 0 is "Not in Universe"; drop it too.
ind_neg <- cps_small %>%
filter(ind != 0) %>%
mutate(ind_lbl = as_factor(ind1990, levels = "labels")) %>%
make_change_table(ind_lbl) %>%
mutate(type = "Industry")
round_tbl <- function(df) {
df %>%
mutate(
across(c(y2019, y2024, change), ~ round(.x)),   # -3 = thousands
pct_change = round(pct_change, 1)                   # 0.1 pp
)
}
occ_neg  <- occ_neg  %>% round_tbl()
ind_neg  <- ind_neg  %>% round_tbl()
# ── 6.  Inspect results ─────────────────────────────────────────────────────
occ_neg %>% arrange(pct_change) %>% print(n = 20)   # worst-hit occupations
ind_neg %>% arrange(pct_change) %>% print(n = 20)   # worst-hit industries
# ── 0.  Libraries ────────────────────────────────────────────────────────────
library(tidyverse)
library(lubridate)
library(ipumsr)
library(janitor)
library(haven)      # labelled → factor
# ── 1.  Read the CPS Basic-Monthly extract (2015, 2019, 2024) ────────────────
cps <- read_ipums_micro("/Users/mtkonczal/Documents/data_folder/cps_00003.xml") %>%
clean_names()
# ── 2.  Prep: keep cohort & two target years ────────────────────────────────
cps_small <- cps %>%
mutate(year_month = make_date(year, month, 1)) %>%
filter(year %in% c(2019, 2024),           # comparison years
age  %in% 22:27,                  # young workers
educ >= 111)                      # BA+ (111 = bachelor's)
# NOTE: wtfinl is already on the correct scale — do NOT rescale or as.numeric()
# ── 3.  Helper to build the summary for any categorical var ─────────────────
make_change_table <- function(df, cat_var, wt = wtfinl) {
# 3a. employment totals by month and category
by_mo <- df %>%
group_by({{ cat_var }}, year_month, year) %>%
summarise(emp = sum({{ wt }}, na.rm = TRUE), .groups = "drop")
# 3b. average across the 12 months in each year
by_yr <- by_mo %>%
group_by({{ cat_var }}, year) %>%
summarise(emp = mean(emp), .groups = "drop")
# 3c. reshape, compute change
out <- by_yr %>%
pivot_wider(names_from = year, values_from = emp, names_prefix = "y") %>%
mutate(change      = y2024 - y2019,
pct_change  = 100 * change / y2019) %>%
filter(change < 0)                       # **negative growth only**
out
}
# ── 4.  Occupations (OCC) ───────────────────────────────────────────────────
#       OCC == 0 is "Not in Universe"; drop it up front.
occ_neg <- cps_small %>%
filter(occ != 0) %>%
# turn labelled integer codes into text so the table is readable
mutate(ind_lbl = as_factor(occ2010, levels = "labels")) %>%
make_change_table(ind_lbl)  %>%
mutate(type = "Occupation")
# ── 5.  Industries (IND) ────────────────────────────────────────────────────
#       IND == 0 is "Not in Universe"; drop it too.
ind_neg <- cps_small %>%
filter(ind != 0) %>%
mutate(ind_lbl = as_factor(ind1990, levels = "labels")) %>%
make_change_table(ind_lbl) %>%
mutate(type = "Industry")
round_tbl <- function(df) {
df %>%
mutate(
across(c(y2019, y2024, change), ~ round(.x)),   # -3 = thousands
pct_change = round(pct_change, 1)                   # 0.1 pp
)
}
occ_neg  <- occ_neg  %>% round_tbl()
ind_neg  <- ind_neg  %>% round_tbl()
# ── 6.  Inspect results ─────────────────────────────────────────────────────
occ_neg %>% arrange(pct_change) %>% print(n = 20)   # worst-hit occupations
ind_neg %>% arrange(pct_change) %>% print(n = 20)   # worst-hit industries
write_csv(rbind(occ_neg, ind_neg) %>% arrange(change), "output/negative_growth_22_27_BA_plus.csv")
# ── 0.  Libraries ────────────────────────────────────────────────────────────
library(tidyverse)
library(lubridate)
library(ipumsr)
library(janitor)
library(haven)      # labelled → factor
# ── 1.  Read the CPS Basic-Monthly extract (2015, 2019, 2024) ────────────────
cps <- read_ipums_micro("/Users/mtkonczal/Documents/data_folder/cps_00003.xml") %>%
clean_names()
# ── 2.  quick helper flags ────────────────────────────────────────────────
cps <- cps %>%
mutate(
year_month  = make_date(year, month, 1),
# labour-force & unemployment definitions
lf_flag     = empstat %in% c(21, 22, 30, 31),   # in labour force
unemp_flag  = empstat %in% c(21, 22)            # unemployed
)
# ── 3.  build the four analysis groups ────────────────────────────────────
cps_groups <- cps %>%
filter(age >= 16) %>%                           # BLS denominator convention
mutate(
group = case_when(
age %in% 22:27 & educ >  111           ~ "22-27 > BA",   # evaluate 1st!
age %in% 22:27 & educ >= 111           ~ "22-27 BA+",
age %in% 22:27                         ~ "22-27 all",
TRUE                                   ~ "All (16+)"
)
)
# ── 4.  monthly unemployment rate by group ────────────────────────────────
ur_month <- cps_groups %>%
group_by(group, year_month) %>%
summarise(
unemp = sum(wtfinl * unemp_flag, na.rm = TRUE),
lf    = sum(wtfinl * lf_flag,    na.rm = TRUE),
.groups = "drop"
) %>%
mutate(urate = unemp / lf)
# ── 5.  annual average unemployment rate (rounded) ────────────────────────
ur_annual <- ur_month %>%
mutate(year = year(year_month)) %>%
group_by(group, year) %>%
summarise(
unemployment_rate = round(mean(urate) * 100, 1),   # percent, 1 dp
.groups = "drop"
) %>%
arrange(group, year)
print(ur_annual, n = Inf)
# ── 0.  Libraries ────────────────────────────────────────────────────────────
library(tidyverse)
library(lubridate)
library(ipumsr)
library(janitor)
library(haven)      # labelled → factor
# ── 1.  Read the CPS Basic-Monthly extract (2015, 2019, 2024) ────────────────
cps <- read_ipums_micro("/Users/mtkonczal/Documents/data_folder/cps_00003.xml") %>%
clean_names()
# ── 2.  quick helper flags ────────────────────────────────────────────────
cps <- cps %>%
mutate(
year_month  = make_date(year, month, 1),
# labour-force & unemployment definitions
lf_flag     = empstat %in% c(21, 22, 30, 31),   # in labour force
unemp_flag  = empstat %in% c(21, 22)            # unemployed
)
# ── 3.  build the four analysis groups ────────────────────────────────────
cps_groups <- cps %>%
filter(age >= 16) %>%                           # BLS denominator convention
mutate(
group = case_when(
age %in% 22:27 & educ >  111           ~ "22-27 BA+",   # evaluate 1st!
age %in% 22:27 & educ == 111           ~ "22-27 BA",
age %in% 22:27                         ~ "22-27 all",
TRUE                                   ~ "All (16+)"
)
)
# ── 4.  monthly unemployment rate by group ────────────────────────────────
ur_month <- cps_groups %>%
group_by(group, year_month) %>%
summarise(
unemp = sum(wtfinl * unemp_flag, na.rm = TRUE),
lf    = sum(wtfinl * lf_flag,    na.rm = TRUE),
.groups = "drop"
) %>%
mutate(urate = unemp / lf)
# ── 5.  annual average unemployment rate (rounded) ────────────────────────
ur_annual <- ur_month %>%
mutate(year = year(year_month)) %>%
group_by(group, year) %>%
summarise(
unemployment_rate = round(mean(urate), 1),   # percent, 1 dp
.groups = "drop"
) %>%
arrange(group, year)
print(ur_annual, n = Inf)
# ── 0.  Libraries ───────────────────────────────────────────────────────────
library(tidyverse)
library(lubridate)
library(ipumsr)
library(janitor)
library(haven)      # for as_factor() if you need labelled → factor later
# ── 1.  Read the CPS Basic-Monthly extract (2015, 2019, 2024) ───────────────
cps <- read_ipums_micro("/Users/mtkonczal/Documents/data_folder/cps_00003.xml") |>
clean_names()
# ── 2.  Core labour-force flags ─────────────────────────────────────────────
# • LABFORCE == 2  → in the labour force (employed **or** unemployed)
# • EMPSTAT  codes
#     10  employed − at work
#     12  employed − absent
#     20, 21, 22  unemployed (20 appears only in pre-1994 data)
cps <- cps |>
mutate(
year_month = make_date(year, month, 1),
lf_flag    = labforce == 2,
unemp_flag = empstat %in% c(20, 21, 22)
)
# ── 3.  Build analysis groups ───────────────────────────────────────────────
cps_groups <- cps |>
filter(age >= 16) |>                     # BLS convention
mutate(
group = case_when(
age %in% 22:27 & educ >  111 ~ "22-27 BA+",
age %in% 22:27 & educ == 111 ~ "22-27 BA",
age %in% 22:27               ~ "22-27 all",
TRUE                         ~ "All (16+)"
)
)
# ── 4.  Monthly unemployment rate by group ──────────────────────────────────
ur_month <- cps_groups |>
group_by(group, year_month) |>
summarise(
unemp = sum(wtfinl * unemp_flag, na.rm = TRUE),
lf    = sum(wtfinl * lf_flag,    na.rm = TRUE),
.groups = "drop"
) |>
mutate(urate = unemp / lf)
# ── 5.  Annual average unemployment rate (percent, 1 dp) ────────────────────
ur_annual <- ur_month |>
mutate(year = year(year_month)) |>
group_by(group, year) |>
summarise(
unemployment_rate = round(mean(urate) * 100, 1),  # convert to %
.groups = "drop"
) |>
arrange(group, year)
print(ur_annual, n = Inf)
cps
unique(cps$year)
# ── 0.  Libraries ───────────────────────────────────────────────────────────
library(tidyverse)
library(lubridate)
library(ipumsr)
library(janitor)
library(haven)      # for as_factor() if you need labelled → factor later
# ── 1.  Read the CPS Basic-Monthly extract (2015, 2019, 2024) ───────────────
cps <- read_ipums_micro("/Users/mtkonczal/Documents/data_folder/cps_00003.xml") |>
clean_names()
# ── 2.  Core labour-force flags ─────────────────────────────────────────────
# • LABFORCE == 2  → in the labour force (employed **or** unemployed)
# • EMPSTAT  codes
#     10  employed − at work
#     12  employed − absent
#     20, 21, 22  unemployed (20 appears only in pre-1994 data)
cps <- cps |>
filter(year %in% c(2015,2019,2024)) %>%
mutate(
year_month = make_date(year, month, 1),
lf_flag    = labforce == 2,
unemp_flag = empstat %in% c(20, 21, 22)
)
# ── 3.  Build analysis groups ───────────────────────────────────────────────
cps_groups <- cps |>
filter(age >= 16) |>                     # BLS convention
mutate(
group = case_when(
age %in% 22:27 & educ >  111 ~ "22-27 BA+",
age %in% 22:27 & educ == 111 ~ "22-27 BA",
age %in% 22:27               ~ "22-27 all",
TRUE                         ~ "All (16+)"
)
)
# ── 4.  Monthly unemployment rate by group ──────────────────────────────────
ur_month <- cps_groups |>
group_by(group, year_month) |>
summarise(
unemp = sum(wtfinl * unemp_flag, na.rm = TRUE),
lf    = sum(wtfinl * lf_flag,    na.rm = TRUE),
.groups = "drop"
) |>
mutate(urate = unemp / lf)
# ── 5.  Annual average unemployment rate (percent, 1 dp) ────────────────────
ur_annual <- ur_month |>
mutate(year = year(year_month)) |>
group_by(group, year) |>
summarise(
unemployment_rate = round(mean(urate) * 100, 1),  # convert to %
.groups = "drop"
) |>
arrange(group, year)
print(ur_annual, n = Inf)
cps_groups
cps_groups$sex
summary(cps_groups$sex)
# ── 0.  Libraries ───────────────────────────────────────────────────────────
library(tidyverse)
library(lubridate)
library(ipumsr)
library(janitor)
library(haven)      # for as_factor() if you need labelled → factor later
# ── 1.  Read the CPS Basic-Monthly extract (2015, 2019, 2024) ───────────────
cps <- read_ipums_micro("/Users/mtkonczal/Documents/data_folder/cps_00003.xml") |>
clean_names()
# ── 2.  Core labour-force flags ─────────────────────────────────────────────
# • LABFORCE == 2  → in the labour force (employed **or** unemployed)
# • EMPSTAT  codes
#     10  employed − at work
#     12  employed − absent
#     20, 21, 22  unemployed (20 appears only in pre-1994 data)
cps <- cps |>
filter(year %in% c(2015,2019,2024)) %>%
mutate(
year_month = make_date(year, month, 1),
lf_flag    = labforce == 2,
unemp_flag = empstat %in% c(20, 21, 22)
)
# ── 3.  Build analysis groups ───────────────────────────────────────────────
cps_groups <- cps |>
filter(age >= 16) |>                     # BLS convention
mutate(
group = case_when(
age %in% 22:27 & educ >  111 ~ "22-27 BA+",
age %in% 22:27 & educ == 111 ~ "22-27 BA",
age %in% 22:27               ~ "22-27 all",
TRUE                         ~ "All (16+)"
)
)
# ── 4.  Monthly unemployment rate by group ──────────────────────────────────
ur_month <- cps_groups |>
group_by(group, year_month, sex) |>
summarise(
unemp = sum(wtfinl * unemp_flag, na.rm = TRUE),
lf    = sum(wtfinl * lf_flag,    na.rm = TRUE),
.groups = "drop"
) |>
mutate(urate = unemp / lf) %>%
ungroup()
# ── 5.  Annual average unemployment rate (percent, 1 dp) ────────────────────
ur_annual <- ur_month |>
mutate(year = year(year_month)) |>
group_by(group, year, sex) |>
summarise(
unemployment_rate = round(mean(urate) * 100, 1),  # convert to %
.groups = "drop"
) |>
arrange(group, year, sex) %>%
ungroup()
print(ur_annual, n = Inf)
# ── 0.  Libraries ───────────────────────────────────────────────────────────
library(tidyverse)
library(lubridate)
library(ipumsr)
library(janitor)
library(haven)      # for as_factor() if you need labelled → factor later
library(govMacroTools)
ny_unrate <- read_csv("data/nyfed_young_BA_unrate.csv")
ny_unrate
ny_unrate <- read_csv("data/nyfed_young_BA_unrate.csv") %>%
clean_names()
ny_unrate
ny_unrate <- read_csv("data/nyfed_young_BA_unrate.csv") %>%
clean_names() %>%
select(-x6, -x7) %>%
inner_join(getFRED("JTSHIR"), by="date")
ny_unrate
ny_unrate <- read_csv("data/nyfed_young_BA_unrate.csv") %>%
clean_names() %>%
select(-x6, -x7) %>%
inner_join(getFRED("JTSHIR"), by="date") %>%
rename(hires = jtshir)
ny_unrate
cor(ny_unrate$hires, ny_unrate$recent_graduates)
cor(ny_unrate$hires, ny_unrate$all_workers)
cor(ny_unrate$hires, ny_unrate$young_workers)
# ── 0.  Libraries ───────────────────────────────────────────────────────────
library(tidyverse)
library(lubridate)
library(slider)   # for slide_dbl()
library(zoo)      # rollapplyr() – easier for 2-var correlations
library(showtext) # optional font for social media images
font_add_google("Roboto Condensed", "roboto"); showtext_auto()
# ── 1.  Data ────────────────────────────────────────────────────────────────
ny_unrate <- read_csv("data/nyfed_young_BA_unrate.csv") %>%      # your CSV
clean_names() %>%                                              # janitor
select(-x6, -x7) %>%                                           # drop junk cols
inner_join(getFRED("JTSHIR"), by = "date") %>%                 # JOLTS hires
rename(hires = jtshir) %>%                                     # clearer name
arrange(date)                                                  # chronological
# ── 2.  4-year (48-month) rolling correlations ─────────────────────────────
window <- 48   # 4 years * 12 months
ny_roll <- ny_unrate %>%
# keep only the columns we need
select(date, hires, recent_graduates, all_workers, young_workers) %>%
# for each unemployment column, run a rolling cor with hires
mutate(across(
.cols  = c(recent_graduates, all_workers, young_workers),
.fns   = ~ rollapplyr(
data.frame(h = hires, u = .x),
width   = window,
FUN     = function(mat) cor(mat[, "h"], mat[, "u"],
use = "complete.obs"),
by.column = FALSE,
fill    = NA,        # leading NAs until the window is full
align   = "right"
),
.names = "corr_{.col}"
)) %>%
# reshape so each series gets its own row per date
pivot_longer(
cols   = starts_with("corr_"),
names_to  = "series",
names_pattern = "corr_(.*)",     # strip the 'corr_' prefix
values_to = "value"
) %>%
mutate(series = str_replace_all(series, "_", " "))   # nicer facet titles
# ── 3.  Plot ────────────────────────────────────────────────────────────────
line_col <- "#394b76"
corr_plot <- ny_roll %>%
ggplot(aes(date, value, colour = series)) +
geom_hline(yintercept = 0, linewidth = .4, linetype = "dashed") +
geom_line(linewidth = 1) +
scale_y_continuous(limits = c(-1, 1), breaks = seq(-1, 1, .25)) +
scale_colour_manual(values = c(
"recent graduates" = "#bf3f3f",
"young workers"    = "#1e8a8a",
"all workers"      = line_col
), guide = guide_legend(title = NULL)) +
labs(
title = "Rolling 4-Year Correlation: JOLTS Hiring Rate vs. Unemployment Rates",
subtitle = "Monthly data, January 2000 – March 2025 · 48-month window (right-aligned)",
caption = "Source: NY Fed young worker unemployment data, BLS JOLTS (series JTSHIR) · @mtkonczal",
x = NULL, y = "Correlation"
) +
theme_classic(base_family = "roboto", base_size = 14) +
theme(
plot.title.position = "plot",
legend.position = "bottom",
legend.key.width = unit(1.3, "cm")
)
# ── 4.  Export for social media (Tweeter / slides) ──────────────────────────
ggsave("figs/rolling_correlations.png", corr_plot,
width = 10, height = 6, dpi = 320)
# ── 0.  Libraries ───────────────────────────────────────────────────────────
library(tidyverse)
library(lubridate)
library(slider)   # for slide_dbl()
library(zoo)      # rollapplyr() – easier for 2-var correlations
library(showtext) # optional font for social media images
font_add_google("Roboto Condensed", "roboto"); showtext_auto()
# ── 1.  Data ────────────────────────────────────────────────────────────────
ny_unrate <- read_csv("data/nyfed_young_BA_unrate.csv") %>%      # your CSV
clean_names() %>%                                              # janitor
select(-x6, -x7) %>%                                           # drop junk cols
inner_join(getFRED("JTSHIR"), by = "date") %>%                 # JOLTS hires
rename(hires = jtshir) %>%                                     # clearer name
arrange(date)                                                  # chronological
# ── 2.  4-year (48-month) rolling correlations ─────────────────────────────
window <- 48   # 4 years * 12 months
ny_roll <- ny_unrate %>%
# keep only the columns we need
select(date, hires, recent_graduates, all_workers, young_workers) %>%
# for each unemployment column, run a rolling cor with hires
mutate(across(
.cols  = c(recent_graduates, all_workers, young_workers),
.fns   = ~ rollapplyr(
data.frame(h = hires, u = .x),
width   = window,
FUN     = function(mat) cor(mat[, "h"], mat[, "u"],
use = "complete.obs"),
by.column = FALSE,
fill    = NA,        # leading NAs until the window is full
align   = "right"
),
.names = "corr_{.col}"
)) %>%
# reshape so each series gets its own row per date
pivot_longer(
cols   = starts_with("corr_"),
names_to  = "series",
names_pattern = "corr_(.*)",     # strip the 'corr_' prefix
values_to = "value"
) %>%
mutate(series = str_replace_all(series, "_", " "))   # nicer facet titles
# ── 3.  Plot ────────────────────────────────────────────────────────────────
line_col <- "#394b76"
corr_plot <- ny_roll %>%
ggplot(aes(date, value, colour = series)) +
geom_hline(yintercept = 0, linewidth = .4, linetype = "dashed") +
geom_line(linewidth = 1) +
scale_y_continuous(limits = c(-1, 1), breaks = seq(-1, 1, .25)) +
scale_colour_manual(values = c(
"recent graduates" = "#bf3f3f",
"young workers"    = "#1e8a8a",
"all workers"      = line_col
), guide = guide_legend(title = NULL)) +
labs(
title = "Rolling 4-Year Correlation: JOLTS Hiring Rate vs. Unemployment Rates",
subtitle = "Monthly data, January 2000 – March 2025 · 48-month window (right-aligned)",
caption = "Source: NY Fed young worker unemployment data, BLS JOLTS (series JTSHIR) · @mtkonczal",
x = NULL, y = "Correlation"
) +
theme_classic(base_family = "roboto", base_size = 14) +
theme(
plot.title.position = "plot",
legend.position = "bottom",
legend.key.width = unit(1.3, "cm")
)
# ── 4.  Export for social media (Tweeter / slides) ──────────────────────────
ggsave("rolling_correlations.png", corr_plot,
width = 10, height = 6, dpi = 320)
corr_plot
